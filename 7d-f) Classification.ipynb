{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7d), e), f) Classification\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge pandas_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pandas\n",
    "import numpy as np\n",
    "import pandas_ml\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import warnings\n",
    "#ignore the future warning and calc error if no sample from a label \n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "#load data and merge both tables to one, separate quality label\n",
    "redwinedata = pandas.read_csv('data/winequality-red.csv', sep =';')\n",
    "whitewinedata = pandas.read_csv('data/winequality-white.csv', sep =';')\n",
    "concat_data = redwinedata.append(whitewinedata, ignore_index=True)\n",
    "y = (concat_data[['quality']])\n",
    "y = y.values.ravel()\n",
    "X = concat_data.drop('quality', axis=1)\n",
    "# convert to nparray\n",
    "X = X.values\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# using scaler to be able to use it on testset with same settings with scaler.transform(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting  and normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Normalizing before or after splitting: https://goo.gl/c1GQpE\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# before testing do scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks:     \n",
    "Macro vs Micro Average in Scores:    \n",
    "macro takes the mean of each labels individual score    \n",
    "micro takes overall recall independant of labels. Take this because we are interested in the overall performance not label-wise    \n",
    "Precision vs Recall in non-binary case:\n",
    "https://datascience.stackexchange.com/questions/32032/precision-and-recall-if-not-binary/32034#32034\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model, fit and predict\n",
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  3  4     5     6    7  8  9  __all__\n",
      "Actual                                         \n",
      "3          0  0    12     9    0  0  0       21\n",
      "4          0  1    82    58    1  0  0      142\n",
      "5          0  0   958   480    4  0  0     1442\n",
      "6          0  0   331  1516   51  0  0     1898\n",
      "7          0  0    22   515  178  0  0      715\n",
      "8          0  0     1    95   34  0  0      130\n",
      "9          0  0     0     1    3  0  0        4\n",
      "__all__    0  1  1406  2674  271  0  0     4352\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00        21\n",
      "          4       1.00      0.01      0.01       142\n",
      "          5       0.68      0.66      0.67      1442\n",
      "          6       0.57      0.80      0.66      1898\n",
      "          7       0.66      0.25      0.36       715\n",
      "          8       0.00      0.00      0.00       130\n",
      "          9       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.61      0.61      0.57      4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = svm.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_train, y_pred_train))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-Set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  3   4    5    6    7   8  9  __all__\n",
      "Actual                                         \n",
      "3          9   0    0    0    0   0  0        9\n",
      "4          0  74    0    0    0   0  0       74\n",
      "5          0   0  696    0    0   0  0      696\n",
      "6          0   0    0  938    0   0  0      938\n",
      "7          0   0    0    0  364   0  0      364\n",
      "8          0   0    0    0    0  63  0       63\n",
      "9          0   0    0    0    0   0  1        1\n",
      "__all__    9  74  696  938  364  63  1     2145\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00         9\n",
      "          4       0.00      0.00      0.00        74\n",
      "          5       0.64      0.63      0.63       696\n",
      "          6       0.54      0.75      0.63       938\n",
      "          7       0.55      0.23      0.33       364\n",
      "          8       0.00      0.00      0.00        63\n",
      "          9       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.54      0.57      0.54      2145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(scaler.transform(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_true, y_test))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model, fit and predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(100, 100), random_state=1)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted   3   4     5     6    7   8  9  __all__\n",
      "Actual                                            \n",
      "3          10   1     4     6    0   0  0       21\n",
      "4           0  57    51    30    4   0  0      142\n",
      "5           1   9  1122   277   33   0  0     1442\n",
      "6           0   2   181  1579  136   0  0     1898\n",
      "7           0   0    23   199  489   4  0      715\n",
      "8           0   2     3    33   51  41  0      130\n",
      "9           0   0     1     0    3   0  0        4\n",
      "__all__    11  71  1385  2124  716  45  0     4352\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.91      0.48      0.62        21\n",
      "          4       0.80      0.40      0.54       142\n",
      "          5       0.81      0.78      0.79      1442\n",
      "          6       0.74      0.83      0.79      1898\n",
      "          7       0.68      0.68      0.68       715\n",
      "          8       0.91      0.32      0.47       130\n",
      "          9       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.76      0.76      0.75      4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = mlp.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_train, y_pred_train))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  3   4    5     6    7   8  9  __all__\n",
      "Actual                                          \n",
      "3          1   0    3     4    1   0  0        9\n",
      "4          1   9   41    19    4   0  0       74\n",
      "5          1   4  430   244   16   1  0      696\n",
      "6          0   3  186   611  135   3  0      938\n",
      "7          0   1   10   160  189   4  0      364\n",
      "8          0   1    3    17   38   4  0       63\n",
      "9          0   0    0     0    1   0  0        1\n",
      "__all__    3  18  673  1055  384  12  0     2145\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.33      0.11      0.17         9\n",
      "          4       0.50      0.12      0.20        74\n",
      "          5       0.64      0.62      0.63       696\n",
      "          6       0.58      0.65      0.61       938\n",
      "          7       0.49      0.52      0.51       364\n",
      "          8       0.33      0.06      0.11        63\n",
      "          9       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.57      0.58      0.57      2145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =  mlp.predict(scaler.transform(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_test, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# set model, fit and predict\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  3  4     5     6  7  8  9  __all__\n",
      "Actual                                       \n",
      "3          0  0     7    14  0  0  0       21\n",
      "4          0  0    60    82  0  0  0      142\n",
      "5          0  0   761   681  0  0  0     1442\n",
      "6          0  0   396  1502  0  0  0     1898\n",
      "7          0  0    41   674  0  0  0      715\n",
      "8          0  0     1   129  0  0  0      130\n",
      "9          0  0     0     4  0  0  0        4\n",
      "__all__    0  0  1266  3086  0  0  0     4352\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00        21\n",
      "          4       0.00      0.00      0.00       142\n",
      "          5       0.60      0.53      0.56      1442\n",
      "          6       0.49      0.79      0.60      1898\n",
      "          7       0.00      0.00      0.00       715\n",
      "          8       0.00      0.00      0.00       130\n",
      "          9       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.41      0.52      0.45      4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = rfc.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_train, y_pred_train))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted  3  4    5     6  7  8  9  __all__\n",
      "Actual                                      \n",
      "3          0  0    4     5  0  0  0        9\n",
      "4          0  0   28    46  0  0  0       74\n",
      "5          0  0  384   312  0  0  0      696\n",
      "6          0  0  177   761  0  0  0      938\n",
      "7          0  0   14   350  0  0  0      364\n",
      "8          0  0    1    62  0  0  0       63\n",
      "9          0  0    0     1  0  0  0        1\n",
      "__all__    0  0  608  1537  0  0  0     2145\n",
      "\n",
      "Classification Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00         9\n",
      "          4       0.00      0.00      0.00        74\n",
      "          5       0.63      0.55      0.59       696\n",
      "          6       0.50      0.81      0.61       938\n",
      "          7       0.00      0.00      0.00       364\n",
      "          8       0.00      0.00      0.00        63\n",
      "          9       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.42      0.53      0.46      2145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(scaler.transform(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pandas_ml.ConfusionMatrix(y_test, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\"+\"Classification Scores:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the results of all the classification algorithms were extremely similar.\n",
    "As expected, the multilayer perceptron has the best fit for the training data. By increasing the number of layers (or layer-sizes), this fit can be increased by a lot. This nicely shows the effect of overfitting, because  there is only a positive effect on the training- but not on the test-set-fit.\n",
    "The Random Forest probably has the worst results because the inputs are continous which makes it harder for a decision tree to work out, beause it has to put them into discrete intervals. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
