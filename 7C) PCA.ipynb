{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "#use pandas to load csv file\n",
    "import pandas as pandas\n",
    "#use numpy to calculate stuff\n",
    "import numpy as np\n",
    "\n",
    "#load data and merge both tables to one, ignore_index to reindex\n",
    "redwinedata = pandas.read_csv('data/winequality-red.csv', sep =';')\n",
    "whitewinedata = pandas.read_csv('data/winequality-white.csv', sep =';')\n",
    "\n",
    "\n",
    "#simplified data for testing\n",
    "#redwinedata = pandas.read_csv('data/red_onlysugar.csv', sep =';')\n",
    "#whitewinedata = pandas.read_csv('data/white_onlysugar.csv', sep =';')\n",
    "\n",
    "concat_data = redwinedata.append(whitewinedata, ignore_index=True)\n",
    "# drop the quality label and normalize the data\n",
    "concat_data = concat_data.drop('quality', axis=1)\n",
    "winearray = concat_data.values\n",
    "winearray_norm = sklearn.preprocessing.scale(winearray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the Principal Components should be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components and their explained variance ratio:\n",
      "[0.2754426  0.22671146 0.14148609 0.08823201 0.06544317 0.05521016\n",
      " 0.04755989 0.04559184 0.03063855 0.02069961 0.00298462]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~timohe/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/23294616/how-to-use-scikit-learn-pca-for-features-reduction-and-know-which-features-are-d\n",
    "pca = PCA()\n",
    "pca.fit(winearray_norm)\n",
    "print(\"Principal Components and their explained variance ratio:\")\n",
    "print(pca.explained_variance_ratio_)  \n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    y=np.cumsum(pca.explained_variance_ratio_),\n",
    "    fill='tozeroy'\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title='Plot Title',\n",
    "    xaxis=dict(\n",
    "        title='x Axis',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='y Axis',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "py.iplot({'data': data, 'layout': {'title': 'Cumultative explained variance ratio', 'font': dict(size=16)}}, filename='basic-area')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this Graph, my desicion would be to include 4 PC, because it explains 73% of the variance while drastcally reducibg the number of coponents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-Composition of the most important PC\n",
    "We now look at the correlation between the features and the principal components to see which of the features play into the principal components. This gives us a hint, which features we could drop for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see https://stackoverflow.com/questions/23294616/how-to-use-scikit-learn-pca-for-features-reduction-and-know-which-features-are-d\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(winearray_norm)\n",
    "#print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2     3     4     5     6     7     8     9     10\n",
      "mean  0.18 -0.01  0.16 -0.01 -0.23  0.00 -0.15 -0.32  0.29  0.30 -0.21\n",
      "std   0.76  0.76  1.28  0.61  0.76  1.12  1.24  1.70  0.95  1.53  1.18\n",
      "min  -0.62 -0.90 -0.92 -0.60 -1.33 -1.19 -1.09 -1.74 -0.65 -1.02 -1.27\n",
      "max   1.08  0.84  1.99  0.57  0.37  1.22  1.65  2.09  1.20  2.48  1.33\n"
     ]
    }
   ],
   "source": [
    "# first take absolute values and then normalize this data to get a better overview\n",
    "comp1 = sklearn.preprocessing.scale(np.absolute(pca.components_[0]))\n",
    "comp2 = sklearn.preprocessing.scale(np.absolute(pca.components_[1]))\n",
    "comp3 = sklearn.preprocessing.scale(np.absolute(pca.components_[2]))\n",
    "comp4 = sklearn.preprocessing.scale(np.absolute(pca.components_[3]))\n",
    "\n",
    "df = pandas.DataFrame([comp1,comp2, comp3, comp4])\n",
    "print(df.describe().drop(['count', '25%', '50%', '75%']).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the dataset above, the features (columns) with the highest means means over all 4 components they have the biggest impact.\n",
    "In this case the ranking would be: 9, 8, 0, 2, 5, 1, 3, 6, 10, 4, 7\n",
    "Additionally one could put a weight according to their cumultative explained variance ratio because the PC which explain more of the variance should have a bigger influence in deciding which feature is important.\n",
    "So let's do the same as before with the variance ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0       1       2       3       4       5       6       7       8   \\\n",
      "mean  0.0357  0.0121 -0.0193  0.0352 -0.0188  0.0074  0.0159 -0.0428 -0.0003   \n",
      "std   0.1144  0.1800  0.2259  0.1122  0.1192  0.2566  0.3065  0.3924  0.1546   \n",
      "min  -0.0699 -0.2042 -0.2524 -0.0674 -0.1885 -0.2705 -0.2482 -0.4794 -0.1485   \n",
      "max   0.1533  0.2300  0.2812  0.1565  0.0832  0.3360  0.4554  0.4738  0.1705   \n",
      "\n",
      "          9       10  \n",
      "mean  0.0062 -0.0312  \n",
      "std   0.1635  0.2687  \n",
      "min  -0.1448 -0.3495  \n",
      "max   0.2189  0.3009  \n"
     ]
    }
   ],
   "source": [
    "#take the explained variance ratio array and use it to weight the component arrays\n",
    "comp1_weighted = pca.explained_variance_ratio_[0] * comp1\n",
    "comp2_weighted = pca.explained_variance_ratio_[1] * comp2\n",
    "comp3_weighted = pca.explained_variance_ratio_[2] * comp3\n",
    "comp4_weighted = pca.explained_variance_ratio_[3] * comp4\n",
    "df_weighted = pandas.DataFrame([comp1_weighted,comp2_weighted, comp3_weighted, comp4_weighted])\n",
    "print(df_weighted.describe().drop(['count', '25%', '50%', '75%']).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altough this ranking is quite different, I will compare those two to make a decision:    \n",
    "0, 3, 6, 1, 5, 9, 8, 2, 4, 10, 7 - weighted     \n",
    "9, 8, 0, 2, 5, 1, 3, 6, 10, 4, 7 - unweighted    \n",
    "\n",
    "It can therefore be argued, that the components 4, 7 and 10 can be dropped (index begins at 0).\n",
    "A look at the head of the data shows us which feature those represent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4               0.7          0.0             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore chlorides, density, alcohol can be dropped!\n",
    "Comparing with excercise a), it does only partly reflect the difference of white and red wines, but must also have found other \"underlying\" factors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
